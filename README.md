# âœ¨VISÃƒO GERAL DO PROJETO
O projeto tenta otimizar um dos processos de RH que Ã© o *matching* de candidatos para a empresa [Decision](https://webrh.decisionbr.com.br/).<br><br>

A dor a ser resolvida nesse projeto consiste em fazer um MVP que seja capaz de responder Ã  seguinte pergunta: dado uma vaga especÃ­fica, quais seriam os melhores candidatos para essa vaga considerando que eu tenho o texto dos currÃ­culos dos candidatos armazenados no sistema, utilizando-se de soluÃ§Ãµes de inteligÃªncia artificial.<br><br>

Para isso, foram utilizadas tÃ©cnicas de *embeddings* e similaridade do cosseno que serÃ£o detalhadas ao longo deste documento.<br><br>

## ðŸŽ¯Objetivo
O projeto em questÃ£o Ã© um MVP para achar os melhores candidatos para uma determinada vaga dado que temos os textos dos currÃ­culos dos candidatos. Deve ser possÃ­vel escolher quais sÃ£o os melhores K candidatos para a vaga. 

## ðŸ’¡SoluÃ§Ã£o Proposta
**A soluÃ§Ã£o proposta consiste no seguinte:**
* Utilizar a API do Gemini para gerar *embeddings* tanto da vaga requerida como dos currÃ­culos dos candidatos cadastrados.<br><br>
* Fazer a similaridade do cosseno entre a vaga especÃ­fica (a vaga que o usuÃ¡rio quer) e todos os candidatos cadastrados no banco vetorial.<br><br>
* Retornar os K candidatos mais similares Ã  vaga, de modo que o usuÃ¡rio pode escolher o valor de K.<br><br>
* Por fim, logar estatÃ­sticas do modelo utilizando MLflow para poder monitorar o desempenho do modelo e possÃ­veis drifts que possam acontecer em produÃ§Ã£o ao longo do tempo.<br><br>

## Stack TecnolÃ³gica:
**Foram utilizados as seguintes tecnologias para construir esse projeto:**
* **Python3 (versÃ£o 3.12)**: linguagem de programaÃ§Ã£o utilizada.<br><br>
* **poetry**: gerenciador de pacotes do python.<br><br>
* **Docker e Docker compose**: conteinerizaÃ§Ã£o e orquestraÃ§Ã£o dos serviÃ§os (API, ChromaDB, Redis e, MLflow).<br><br>
* **ChromaDB**: banco vetorial para armazenar e consultar embeddings semÃ¢nticos.<br><br>
* **Redis**: armazenamento chave-valor em memÃ³ria, de alta performance.<br><br>
* **MLflow**: rastreamento de experimentos (parÃ¢metros, mÃ©tricas e artefatos).<br><br>
* **Flask**: microframework web para a API.<br><br>
* **Gunicorn**: servidor WSGI para produÃ§Ã£o.<br><br>
* **Geimini-API**: API do modelo LLM.<br><br>



# ESTRUTURA DO PROJETO
```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ config.py
â”œâ”€â”€ database
â”‚Â Â  â”œâ”€â”€ READ.ME.txt
â”‚Â Â  â”œâ”€â”€ applicants.json
â”‚Â Â  â”œâ”€â”€ candidates_dim3072.jsonl
â”‚Â Â  â”œâ”€â”€ prospects.json
â”‚Â Â  â””â”€â”€ vagas.json
â”œâ”€â”€ docker
â”‚Â Â  â””â”€â”€ entrypoint.sh
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ run.py
â”œâ”€â”€ scripts
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ export_data.py
â”‚Â Â  â”œâ”€â”€ generate_chromadb_file.py
â”‚Â Â  â”œâ”€â”€ generate_embeddings.py
â”‚Â Â  â””â”€â”€ import_data.py
â”œâ”€â”€ src
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ app.py
â”‚Â Â  â”œâ”€â”€ extensions.py
â”‚Â Â  â”œâ”€â”€ models.py
â”‚Â Â  â”œâ”€â”€ routes.py
â”‚Â Â  â”œâ”€â”€ services
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Data.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ chromadb_info.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ gemini_api.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ log.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ retrieve_data.py
â”‚Â Â  â”œâ”€â”€ static
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ css
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ style.css
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ img
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ decision_logo.png
â”‚Â Â  â”‚Â Â  â””â”€â”€ js
â”‚Â Â  â”‚Â Â      â””â”€â”€ script.js
â”‚Â Â  â””â”€â”€ templates
â”‚Â Â      â””â”€â”€ index.html
â”œâ”€â”€ .env.sample
â””â”€â”€ wsgi.py
```

### Explicando os arquivos que estÃ£o na raiz do projeto:
* **Dockerfile:** arquivo de configuraÃ§Ã£o do Docker, foi utilizado para gerar um container da API do Flask <br><br>
* **LICENSE**: arquivo de licensa do projeto (licenciado sob a MIT License).<br><br>
* **README.md**: este arquivo, com instruÃ§Ãµes e documentaÃ§Ã£o do projeto.<br><br>
* **config.py**: arquivo usado no padrÃ£o Application Factory do Flask, centraliza as configuraÃ§Ãµes para *development*, *test* e *production* (geralmente lendo variÃ¡veis do ambiente/.env).<br><br>
* **docker-compose.yml**: arquivo de configuraÃ§Ã£o do Docker compose, Ã© responsÃ¡vel por declarar os serviÃ§os do sistema bem como configurar o ambiente de cada um deles.<br><br>
* **poetry.lock**: arquivo de lock do Poetry, tem a responsabilidade de armazenar e travar as versÃµes de cada dependÃªncia na Ã¡rvore de dependÃªncias do projeto para garantir a reprodutibilidade.<br><br>
* **pyproject.toml**: arquivo de configuraÃ§Ã£o do Poetry e metadados do projeto, Ã© responsÃ¡vel por armazenar as bibliotecas utilizadas no projeto bem como algumas informaÃ§Ãµes gerais.<br><br>
* **run.py**: arquivo gerado pelo padrÃ£o factory do Flask, Ã© utilizado quando se quer executar a aplicaÃ§Ã£o em modo development utilizando o comando "poetry run python3 run.py", nÃ£o Ã© utilizado em produÃ§Ã£o.<br><br>
* **wsgi.py**: arquivo que inicia a aplicaÃ§Ã£o em produÃ§Ã£o. Ã‰ utilizado pelo servidor web *gunicorn* para iniciar o servidor python da API, ele contÃ©m tudo que Ã© preciso para criar e executar a aplicaÃ§Ã£o.<br><br>
* **.env.sample**: arquivo que possui uma amostra das variÃ¡veis de ambiente do projeto, basicamente possui o valor de todas as variÃ¡veis de ambiente menos a GEMINI_API_KEY, por questÃµes de seguranÃ§a. O arquivo .env deve ser uma cÃ³pia desse arquivo, sÃ³ que nele vocÃª deve preencher o valor de GEMINI_API_KEY.<br><br>

### Explicando os arquivos que estÃ£o na pasta docker/:
* **entrypoint.sh**: arquivo que Ã© executado quando Ã© feito o run da imagem docker. Seu propÃ³sito Ã© fazer algumas configuraÃ§Ãµes iniciais antes de iniciar a API Flask de fato, como fazer o import dos embeddings dos candidatos e definir o exemperimento no MLflow.<br><br>

### Explicando os arquivos que estÃ£o na pasta scripts/:
* **__init__.py**: arquivo que torna a pasta scripts um mÃ³dulo. Seu propÃ³sito Ã© deixar a importaÃ§Ã£o mais fÃ¡cil.<br><br>
* **export_data.py**: exporta dados do banco vetorial ChromaDB para um arquivo .jsonl. Isso Ã© Ãºtil para salvar os embeddings e fazer o load desses dados quando o programa rodar em outra mÃ¡quina, por exemplo, nÃ£o precisando gerar os embeddings do zero novamente. NÃ£o Ã© usado em produÃ§Ã£o, mas foi usado em desenvolvimento para gerar o arquivo candidates_dim3072.jsonl.<br><br>
* **generate_embeddings.py**: pega o arquivo de candidatos em database/applicants.json que estava dentro do Redis e gera os embeddings de cada candidato. Pega-se o campo "cv_pt" de cada candidato e gera-se os embeddings desse campo que Ã© salvo no ChromaDB, perceba que esse script foi usado para gerar os embeddings e salvar no ChromaDB enquando o arquivo de cima "export_data.py" Ã© usado para fazer o export desses dados para um arquivo.<br><br>
* **import_data.py**: arquivo que carrega o arquivo de embeddings database/candidates_dim3072.jsonl para dentro do ChromaDB. Ele Ã© chamado pelo docker quando inicia o serviÃ§o da API que sÃ³ Ã© iniciada quando esse import termina, ou seja, ele Ã© bloqueante.<br><br>

### Explicando os arquivos que estÃ£o na pasta src/:
* **__init__.py**: arquivo que torna a pasta src um mÃ³dulo. Seu propÃ³sito Ã© deixar a importaÃ§Ã£o mais fÃ¡cil.<br><br>
* **app.py**: arquivo gerado pelo padrÃ£o factory do Flask, mas nÃ£o utilizado.<br><br>
* **extensions.py**: arquivo gerado pelo padrÃ£o factory do Flask, mas nÃ£o utilizado.<br><br>
* **models.py**: arquivo gerado pelo padrÃ£o factory do Flask, mas nÃ£o utilizado.<br><br>
* **routes.py**: arquivo gerado pelo padrÃ£o factory do Flask, contÃ©m as rotas da API.<br><br>
* **templates/index.html**: pÃ¡gina web do projeto.<br><br>
* **static/css/style.css**: css da pÃ¡gina web do projeto.<br><br>
* **static/img/decision_logo.png**: logo da Decision que Ã© usado na pÃ¡gina web.<br><br>
* **static/js/script.js**: javascript da pÃ¡gina web.<br><br>
* **services/__init__.py**: arquivo que torna a pasta services um mÃ³dulo. Seu propÃ³sito Ã© deixar a importaÃ§Ã£o mais fÃ¡cil.<br><br>
* **services/chromadb_info.py**: arquivo usado para interagir com o ChromaDB apenas em ambiente de desenvolvimento (excluir dados, ver embeddings, coleÃ§Ãµes, etc).<br><br>
* **services/Data.py**: arquivo que contÃ©m a classe Data, que Ã© responsÃ¡vel por se comunicar com o Redis e acessar os arquivos de vagas e candidatos dentro da pasta database.<br><br>
* **services/gemini_api.py**: arquivo que contÃ©m a classe Model, que encapsula a API do Gemini para gerar embeddings. Ã‰ responsÃ¡vel por interagir com a API do Gemini para gerar embeddings.<br><br>
* **services/log.py**: arquivo responsÃ¡vel por implementar a classe Log, que faz integraÃ§Ã£o com o MLflow via API.<br><br>
* **services/retrieve_data.py**: arquivo responsÃ¡vel por implementar a classe ChromaDB como um singleton. Essa classe Ã© responsÃ¡vel por se comunicar com o banco vetorial ChromaDB.<br><br>


# INSTRUÃ‡Ã•ES DE DEPLOY LOCAL
Para executar o projeto local, vocÃª precisa ter o docker e o docker compose instalado na sua mÃ¡quina e entÃ£o executar os seguintes passos:
* Baixe o projeto com o seguinte comando:
```bash
git clone https://github.com/valteci/Datathon.git
```
* Entre no diretÃ³rio do projeto com o comando:
```bash
cd Datathon
```
* Crie uma pasta chamada "database" na raiz do projeto. A versÃ£o entregue aos professores jÃ¡ possui essa pasta, nÃ£o precisa criÃ¡-la caso seja o professor.<br><br>
* Baixe [esse arquivo](https://drive.google.com/file/d/16TV4tOEU45j0Uq457uU2JIp8vEx9lHuv/view?usp=sharing) e coloque-o dentro da pasta database. A versÃ£o entregue aos professores jÃ¡ possui esse arquivo, nÃ£o precisa baixÃ¡-lo caso seja o professor.<br><br>
* Criar o arquivo ".env" na raiz do projeto, ele Ã© uma cÃ³pia do arquivo .env.sample que jÃ¡ vem no projeto, mas vocÃª precisa preencher a variÃ¡vel de ambiente GEMINI_API_KEY com uma chave vÃ¡lida dentro do arquivo .env. A versÃ£o entregue aos professores jÃ¡ possui um .env vÃ¡lido, nÃ£o precisa criÃ¡-lo caso seja um professor.<br><br>
* Na raiz do projeto, executar o seguinte comando para rodar a aplicaÃ§Ã£o:
```bash
docker compose up --build
```
* Monitorar a saÃ­da do comando no passo anterior. Quando os serviÃ§os subirem, o servidor vai precisar fazer o import dos embeddings dos candidatos, o que vai demorar de 1 a 2 minutos na primeira vez que o sistema for executado. A aplicaÃ§Ã£o estarÃ¡ pronta para uso quando os imports forem concluÃ­dos (done) e aparecer uma mensagem parecida com essa "[INFO] Booting worker with pid..."<br><br>
* Acesse a aplicaÃ§Ã£o por meio do endereÃ§o [localhost:5000](http://localhost:5000)<br><br>


# DEPLOY NO GOOGLE CLOUD
Essa projeto foi implantado do google cloud e pode ser acessado pelo seguinte link: [http://34.39.160.178:5000/](http://34.39.160.178:5000/)


# ROTAS E EXEMPLOS DE CHAMADAS A API


# FLUXO DE PROCESSAMENTO

